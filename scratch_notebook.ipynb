{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Reforming embedding vector and storing to database"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "     ID    Name         0         1         2         3         4         5  \\\n0     0  Taufiq  0.069142 -0.073751  0.006923 -0.046116 -0.011825 -0.039105   \n1     0  Taufiq  0.057503 -0.033950  0.035315 -0.040212 -0.013937 -0.076416   \n2     0  Taufiq  0.054656 -0.051435 -0.006260 -0.039825  0.004260 -0.054023   \n3     0  Taufiq  0.055511 -0.042475  0.009054 -0.048174 -0.018067 -0.059855   \n4     0  Taufiq  0.070662 -0.015240  0.032206 -0.069778  0.001434 -0.065043   \n..   ..     ...       ...       ...       ...       ...       ...       ...   \n331  23  Shamim  0.014831 -0.067789  0.014980  0.011712 -0.003217 -0.025228   \n332  23  Shamim -0.006516 -0.060191  0.008171  0.017038  0.018588 -0.020872   \n333  23  Shamim -0.003160 -0.058766  0.012385  0.044061 -0.011214 -0.020975   \n334  23  Shamim -0.014060 -0.061962 -0.011366  0.012576 -0.004787 -0.020102   \n335  23  Shamim -0.002324 -0.046333  0.024917 -0.011361  0.023973 -0.032599   \n\n            6         7  ...       502       503       504       505  \\\n0   -0.083435  0.058255  ...  0.001195  0.019125  0.126797 -0.000127   \n1   -0.065176  0.061475  ...  0.022566  0.018541  0.109560  0.011451   \n2   -0.064597  0.065633  ...  0.000886  0.025934  0.109343  0.000195   \n3   -0.064681  0.071633  ...  0.018057  0.034947  0.105358  0.017326   \n4   -0.059696  0.064626  ...  0.022270  0.017610  0.106384  0.011225   \n..        ...       ...  ...       ...       ...       ...       ...   \n331  0.006663  0.048180  ... -0.033449  0.012720  0.005864 -0.032764   \n332  0.006240  0.029679  ... -0.072534 -0.006747 -0.013288 -0.018142   \n333  0.056631 -0.003419  ... -0.048785  0.052804 -0.013514 -0.027410   \n334  0.002698  0.018598  ... -0.075385  0.010792 -0.013015 -0.023853   \n335  0.017923  0.033043  ... -0.052843  0.006375 -0.001878 -0.023565   \n\n          506       507       508       509       510       511  \n0   -0.010205  0.016986  0.031015 -0.016855 -0.053175 -0.056179  \n1   -0.012414  0.012907  0.077091 -0.030490 -0.014722 -0.026513  \n2    0.024317  0.049969  0.027593 -0.002905 -0.037219 -0.036503  \n3    0.002253  0.015173  0.033482 -0.032342 -0.058163 -0.050611  \n4   -0.030861 -0.006642  0.065881 -0.032527 -0.020178 -0.050314  \n..        ...       ...       ...       ...       ...       ...  \n331  0.038940  0.008811 -0.009773 -0.051231  0.041074  0.028078  \n332  0.050029  0.044783 -0.003868 -0.041999  0.008945  0.021267  \n333  0.037022  0.022050 -0.014504 -0.056171  0.044675  0.024010  \n334  0.034429  0.008378 -0.040125 -0.062277  0.053744  0.033205  \n335  0.034532  0.038842  0.012187 -0.049598  0.033395  0.021893  \n\n[336 rows x 514 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Name</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>...</th>\n      <th>502</th>\n      <th>503</th>\n      <th>504</th>\n      <th>505</th>\n      <th>506</th>\n      <th>507</th>\n      <th>508</th>\n      <th>509</th>\n      <th>510</th>\n      <th>511</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Taufiq</td>\n      <td>0.069142</td>\n      <td>-0.073751</td>\n      <td>0.006923</td>\n      <td>-0.046116</td>\n      <td>-0.011825</td>\n      <td>-0.039105</td>\n      <td>-0.083435</td>\n      <td>0.058255</td>\n      <td>...</td>\n      <td>0.001195</td>\n      <td>0.019125</td>\n      <td>0.126797</td>\n      <td>-0.000127</td>\n      <td>-0.010205</td>\n      <td>0.016986</td>\n      <td>0.031015</td>\n      <td>-0.016855</td>\n      <td>-0.053175</td>\n      <td>-0.056179</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>Taufiq</td>\n      <td>0.057503</td>\n      <td>-0.033950</td>\n      <td>0.035315</td>\n      <td>-0.040212</td>\n      <td>-0.013937</td>\n      <td>-0.076416</td>\n      <td>-0.065176</td>\n      <td>0.061475</td>\n      <td>...</td>\n      <td>0.022566</td>\n      <td>0.018541</td>\n      <td>0.109560</td>\n      <td>0.011451</td>\n      <td>-0.012414</td>\n      <td>0.012907</td>\n      <td>0.077091</td>\n      <td>-0.030490</td>\n      <td>-0.014722</td>\n      <td>-0.026513</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>Taufiq</td>\n      <td>0.054656</td>\n      <td>-0.051435</td>\n      <td>-0.006260</td>\n      <td>-0.039825</td>\n      <td>0.004260</td>\n      <td>-0.054023</td>\n      <td>-0.064597</td>\n      <td>0.065633</td>\n      <td>...</td>\n      <td>0.000886</td>\n      <td>0.025934</td>\n      <td>0.109343</td>\n      <td>0.000195</td>\n      <td>0.024317</td>\n      <td>0.049969</td>\n      <td>0.027593</td>\n      <td>-0.002905</td>\n      <td>-0.037219</td>\n      <td>-0.036503</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>Taufiq</td>\n      <td>0.055511</td>\n      <td>-0.042475</td>\n      <td>0.009054</td>\n      <td>-0.048174</td>\n      <td>-0.018067</td>\n      <td>-0.059855</td>\n      <td>-0.064681</td>\n      <td>0.071633</td>\n      <td>...</td>\n      <td>0.018057</td>\n      <td>0.034947</td>\n      <td>0.105358</td>\n      <td>0.017326</td>\n      <td>0.002253</td>\n      <td>0.015173</td>\n      <td>0.033482</td>\n      <td>-0.032342</td>\n      <td>-0.058163</td>\n      <td>-0.050611</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>Taufiq</td>\n      <td>0.070662</td>\n      <td>-0.015240</td>\n      <td>0.032206</td>\n      <td>-0.069778</td>\n      <td>0.001434</td>\n      <td>-0.065043</td>\n      <td>-0.059696</td>\n      <td>0.064626</td>\n      <td>...</td>\n      <td>0.022270</td>\n      <td>0.017610</td>\n      <td>0.106384</td>\n      <td>0.011225</td>\n      <td>-0.030861</td>\n      <td>-0.006642</td>\n      <td>0.065881</td>\n      <td>-0.032527</td>\n      <td>-0.020178</td>\n      <td>-0.050314</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>331</th>\n      <td>23</td>\n      <td>Shamim</td>\n      <td>0.014831</td>\n      <td>-0.067789</td>\n      <td>0.014980</td>\n      <td>0.011712</td>\n      <td>-0.003217</td>\n      <td>-0.025228</td>\n      <td>0.006663</td>\n      <td>0.048180</td>\n      <td>...</td>\n      <td>-0.033449</td>\n      <td>0.012720</td>\n      <td>0.005864</td>\n      <td>-0.032764</td>\n      <td>0.038940</td>\n      <td>0.008811</td>\n      <td>-0.009773</td>\n      <td>-0.051231</td>\n      <td>0.041074</td>\n      <td>0.028078</td>\n    </tr>\n    <tr>\n      <th>332</th>\n      <td>23</td>\n      <td>Shamim</td>\n      <td>-0.006516</td>\n      <td>-0.060191</td>\n      <td>0.008171</td>\n      <td>0.017038</td>\n      <td>0.018588</td>\n      <td>-0.020872</td>\n      <td>0.006240</td>\n      <td>0.029679</td>\n      <td>...</td>\n      <td>-0.072534</td>\n      <td>-0.006747</td>\n      <td>-0.013288</td>\n      <td>-0.018142</td>\n      <td>0.050029</td>\n      <td>0.044783</td>\n      <td>-0.003868</td>\n      <td>-0.041999</td>\n      <td>0.008945</td>\n      <td>0.021267</td>\n    </tr>\n    <tr>\n      <th>333</th>\n      <td>23</td>\n      <td>Shamim</td>\n      <td>-0.003160</td>\n      <td>-0.058766</td>\n      <td>0.012385</td>\n      <td>0.044061</td>\n      <td>-0.011214</td>\n      <td>-0.020975</td>\n      <td>0.056631</td>\n      <td>-0.003419</td>\n      <td>...</td>\n      <td>-0.048785</td>\n      <td>0.052804</td>\n      <td>-0.013514</td>\n      <td>-0.027410</td>\n      <td>0.037022</td>\n      <td>0.022050</td>\n      <td>-0.014504</td>\n      <td>-0.056171</td>\n      <td>0.044675</td>\n      <td>0.024010</td>\n    </tr>\n    <tr>\n      <th>334</th>\n      <td>23</td>\n      <td>Shamim</td>\n      <td>-0.014060</td>\n      <td>-0.061962</td>\n      <td>-0.011366</td>\n      <td>0.012576</td>\n      <td>-0.004787</td>\n      <td>-0.020102</td>\n      <td>0.002698</td>\n      <td>0.018598</td>\n      <td>...</td>\n      <td>-0.075385</td>\n      <td>0.010792</td>\n      <td>-0.013015</td>\n      <td>-0.023853</td>\n      <td>0.034429</td>\n      <td>0.008378</td>\n      <td>-0.040125</td>\n      <td>-0.062277</td>\n      <td>0.053744</td>\n      <td>0.033205</td>\n    </tr>\n    <tr>\n      <th>335</th>\n      <td>23</td>\n      <td>Shamim</td>\n      <td>-0.002324</td>\n      <td>-0.046333</td>\n      <td>0.024917</td>\n      <td>-0.011361</td>\n      <td>0.023973</td>\n      <td>-0.032599</td>\n      <td>0.017923</td>\n      <td>0.033043</td>\n      <td>...</td>\n      <td>-0.052843</td>\n      <td>0.006375</td>\n      <td>-0.001878</td>\n      <td>-0.023565</td>\n      <td>0.034532</td>\n      <td>0.038842</td>\n      <td>0.012187</td>\n      <td>-0.049598</td>\n      <td>0.033395</td>\n      <td>0.021893</td>\n    </tr>\n  </tbody>\n</table>\n<p>336 rows Ã— 514 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "df = pd.read_csv('/home/nayan/MIS_Face_DB.csv')\n",
    "df.head(500)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame()\n",
    "db = []\n",
    "for i in range(len(df)):\n",
    "    a = df.loc[i]\n",
    "    em = a[2:514]\n",
    "    em = np.array(em)\n",
    "    entry = list(a[0:2])\n",
    "    entry.append(str(em))\n",
    "    db.append(entry)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "db = np.array(db)\n",
    "print(db)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "  index    name                                          embedding\n0     0  Taufiq  [0.06914231 -0.073750846 0.00692339 -0.0461162...\n1     0  Taufiq  [0.05750265 -0.033950254 0.035315044 -0.040212...\n2     0  Taufiq  [0.05465557 -0.05143523 -0.0062603485 -0.03982...\n3     0  Taufiq  [0.055511218 -0.04247488 0.009053543 -0.048174...\n4     0  Taufiq  [0.070662454 -0.015239747 0.032205828 -0.06977...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>name</th>\n      <th>embedding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Taufiq</td>\n      <td>[0.06914231 -0.073750846 0.00692339 -0.0461162...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>Taufiq</td>\n      <td>[0.05750265 -0.033950254 0.035315044 -0.040212...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>Taufiq</td>\n      <td>[0.05465557 -0.05143523 -0.0062603485 -0.03982...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>Taufiq</td>\n      <td>[0.055511218 -0.04247488 0.009053543 -0.048174...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>Taufiq</td>\n      <td>[0.070662454 -0.015239747 0.032205828 -0.06977...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df = pd.DataFrame(db, columns=['index', 'name', 'embedding'])\n",
    "out_df['embedding'] = out_df['embedding'].replace(to_replace='\\n', value='', regex=True)\n",
    "out_df.head()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "#out_df.to_csv('database_final4.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Communicating with werver"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import numpy as np\n",
    "def connect_to_DB():\n",
    "    odbc_driver = '{ODBC Driver 17 for SQL Server}'\n",
    "    native_driver = '{SQL Server Native Client 11.0}'\n",
    "\n",
    "    driver = native_driver\n",
    "    conn = None\n",
    "    if sys.platform == 'linux':\n",
    "        driver = odbc_driver\n",
    "    else:\n",
    "        driver = native_driver\n",
    "    conn = pyodbc.connect(\n",
    "        f\"\"\"Driver={driver};\n",
    "        Server=192.168.100.161;\n",
    "        Trusted_Connection=no;\n",
    "        Database=ShwapnoCustomerFaceEmbeddings;\n",
    "        UID=sa;\n",
    "        PWD=dataport;\"\"\"\n",
    "    )\n",
    "    return conn\n",
    "\n",
    "connection = connect_to_DB()\n",
    "connection.autocommit = True\n",
    "cursor = connection.cursor()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT * FROM mytable\")\n",
    "rows = cursor.fetchall()\n",
    "#cursor.execute(\"SELECT WORK_ORDER.TYPE,WORK_ORDER.STATUS, WORK_ORDER.BASE_ID, WORK_ORDER.LOT_ID FROM WORK_ORDER\")\n",
    "for row in rows:\n",
    "    a = row.embedding.split(' ')\n",
    "    print(a[1],type(a), len(a))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Base Code"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pyodbc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def get_group_info(group_id, group_info, applied_date):\n",
    "    group_info = pd.DataFrame(list(zip(group_id, group_info, applied_date)),\n",
    "                              columns=['GroupId', 'GroupInfo', 'AppliedDate'])\n",
    "    return group_info\n",
    "\n",
    "\n",
    "def get_master_data(training_id, training_date, write_back_time, df):\n",
    "    df.rename(columns={\n",
    "        #     'CustomerCode': 'customer_code',\n",
    "        '1': 'day_1',\n",
    "        '2': 'day_2',\n",
    "        '3': 'day_3',\n",
    "        '4': 'day_4',\n",
    "        '5': 'day_5',\n",
    "        '6': 'day_6',\n",
    "        '7': 'day_7',\n",
    "        '8': 'day_8'\n",
    "    }, inplace=True)\n",
    "    yyyy = datetime.today().year\n",
    "    mm = datetime.today().strftime('%m')\n",
    "    datetime_object = datetime.strptime(str(mm), \"%m\")\n",
    "    full_month_name = datetime_object.strftime(\"%B\")\n",
    "    full_month_name = full_month_name + \" - \" + str(yyyy)[2:]\n",
    "    master_info = pd.DataFrame(\n",
    "        columns=['TrainingId', 'TrainingDate', 'ForecustingFor', 'SourceDateStart', 'SourceDateEnd', 'WriteBackTime',\n",
    "                 'ForecastedMonth'])\n",
    "    master_info = master_info.append({'TrainingId': training_id,\n",
    "                                      'TrainingDate': training_date,\n",
    "                                      'ForecustingFor': str(yyyy) + str(mm),\n",
    "                                      'SourceDateStart': df['day_8'].min(),\n",
    "                                      'SourceDateEnd': df['day_1'].max(),\n",
    "                                      'WriteBackTime': write_back_time,\n",
    "                                      'ForecastedMonth': full_month_name}, ignore_index=True)\n",
    "    return master_info\n",
    "\n",
    "\n",
    "def _connect_to_lapsedb():\n",
    "    odbc_driver = '{ODBC Driver 17 for SQL Server}'\n",
    "    native_driver = '{SQL Server Native Client 11.0}'\n",
    "\n",
    "    driver = native_driver\n",
    "    conn = None\n",
    "    if sys.platform == 'linux':\n",
    "        driver = odbc_driver\n",
    "    else:\n",
    "        driver = native_driver\n",
    "    conn = pyodbc.connect(\n",
    "        f\"\"\"Driver={driver};\n",
    "        Server=192.168.11.206;\n",
    "        Database=LapseDB;\n",
    "        Trusted_Connection=no;\n",
    "        UID=sa;\n",
    "        PWD=flexiload;\"\"\"\n",
    "    )\n",
    "    return conn\n",
    "\n",
    "\n",
    "def _connect_to_epsmirror():\n",
    "    odbc_driver = '{ODBC Driver 17 for SQL Server}'\n",
    "    native_driver = '{SQL Server Native Client 11.0}'\n",
    "\n",
    "    driver = native_driver\n",
    "    conn = None\n",
    "    if sys.platform == 'linux':\n",
    "        driver = odbc_driver\n",
    "    else:\n",
    "        driver = native_driver\n",
    "    conn = pyodbc.connect(\n",
    "        f\"\"\"Driver={driver};\n",
    "        Server=192.168.11.200;\n",
    "        Trusted_Connection=no;\n",
    "        Database=EPSMirror;\n",
    "        UID=sa;\n",
    "        PWD=flexiload;\"\"\"\n",
    "    )\n",
    "    return conn\n",
    "\n",
    "\n",
    "class LapseDBUtil:\n",
    "    def _init_(self):\n",
    "        self.connection = _connect_to_lapsedb()\n",
    "        self.connection.autocommit = True\n",
    "        self.cursor = self.connection.cursor()\n",
    "        print(\"Connected to LapseDB\")\n",
    "\n",
    "        self.connection_epsmirror = _connect_to_epsmirror()\n",
    "        self.connection_epsmirror.autocommit = True\n",
    "        self.cursor_epsmirror = self.connection_epsmirror.cursor()\n",
    "        print(\"Connected to EPSMirror\")\n",
    "\n",
    "    def create_table(self, table_name):\n",
    "        if table_name == \"LapseDetails\":\n",
    "            try:\n",
    "                # self.cursor.execute(\"DROP TABLE NEXT_MONTH_PURCHASE_AMOUNT;\")\n",
    "                self.cursor.execute(\"CREATE TABLE LapseDetails(\" +\n",
    "                                    \"TrainingId INT,\" +\n",
    "                                    \"CustomerCode VARCHAR(20),\" +\n",
    "                                    \"PredictedGroup INT,\" +\n",
    "                                    \");\")\n",
    "                self.connection.commit()\n",
    "                print(\"LapseDetails Table Created\")\n",
    "            except Exception as e:\n",
    "                if \"already an object\" in str(e):\n",
    "                    pass\n",
    "                else:\n",
    "                    print(f'Error: {e}')\n",
    "        elif table_name == \"LapseMaster\":\n",
    "            try:\n",
    "                # self.cursor.execute(\"DROP TABLE NEXT_MONTH_PURCHASE_AMOUNT;\")\n",
    "                self.cursor.execute(\"CREATE TABLE LapseMaster(\" +\n",
    "                                    \"TrainingId INT PRIMARY KEY,\" +\n",
    "                                    \"TrainingDate DATETIME,\" +\n",
    "                                    \"ForecustingFor VARCHAR(6),\" +\n",
    "                                    \"SourceDateStart DATETIME,\" +\n",
    "                                    \"SourceDateEnd DATETIME,\" +\n",
    "                                    \"WriteBackTime DATETIME,\" +\n",
    "                                    \"ForecastedMonth VARCHAR(13),\" +\n",
    "                                    \");\")\n",
    "                self.connection.commit()\n",
    "                print(\"LapseMaster Table Created\")\n",
    "            except Exception as e:\n",
    "                if \"already an object\" in str(e):\n",
    "                    pass\n",
    "                else:\n",
    "                    print(f'Error: {e}')\n",
    "        elif table_name == \"LapsePredictedGroup\":\n",
    "            try:\n",
    "                # self.cursor.execute(\"DROP TABLE NEXT_MONTH_PURCHASE_AMOUNT;\")\n",
    "                self.cursor.execute(\"CREATE TABLE LapsePredictedGroup(\" +\n",
    "                                    \"GroupId INT PRIMARY KEY,\" +\n",
    "                                    \"GroupInfo VARCHAR(20),\" +\n",
    "                                    \"AppliedDate DATETIME,\" +\n",
    "                                    \");\")\n",
    "                self.connection.commit()\n",
    "                print(\"LapsePredictedGroup Table Created\")\n",
    "            except Exception as e:\n",
    "                if \"already an object\" in str(e):\n",
    "                    pass\n",
    "                else:\n",
    "                    print(f'Error: {e}')\n",
    "        else:\n",
    "            print(\"Table Name not in Schema\")\n",
    "\n",
    "    def insert(self, table_name, data_df):\n",
    "        if table_name == \"LapseDetails\":\n",
    "            sql = \"INSERT INTO LapseDetails (TrainingId, CustomerCode, PredictedGroup) \" \\\n",
    "                  \"VALUES (?, ?, ?)\"\n",
    "            print(\"Inserting into LapseDetails\")\n",
    "        elif table_name == \"LapseMaster\":\n",
    "            sql = \"INSERT INTO LapseMaster (TrainingId, TrainingDate, ForecustingFor, SourceDateStart, SourceDateEnd, WriteBackTime, ForecastedMonth) \" \\\n",
    "                  \"VALUES (?, ?, ?, ?, ?, ?, ?)\"\n",
    "            print(\"Inserting into LapseMaster\")\n",
    "        elif table_name == \"LapsePredictedGroup\":\n",
    "            sql = \"INSERT INTO LapsePredictedGroup (GroupId, GroupInfo, AppliedDate) \" \\\n",
    "                  \"VALUES (?, ?, ?)\"\n",
    "            print(\"Inserting into LapsePredictedGroup\")\n",
    "        try:\n",
    "            self.cursor.executemany(sql, data_df.values.tolist())\n",
    "            self.connection.commit()\n",
    "            print('Rows inserted')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    def get_purchase_dates(self):\n",
    "        try:\n",
    "            self.cursor_epsmirror.execute(\"EXEC SP_TrainingDateSetLapsePrediction 'Date'\")\n",
    "            # self.connection_epsmirror.commit()\n",
    "            columns = [column[0] for column in self.cursor_epsmirror.description]\n",
    "            data = self.cursor_epsmirror.fetchall()\n",
    "            rows = []\n",
    "            for customer in data:\n",
    "                row = []\n",
    "                for item in customer:\n",
    "                    row.append(item)\n",
    "                rows.append(row)\n",
    "            data_df = pd.DataFrame(rows, columns=columns)\n",
    "            for column in data_df.columns:\n",
    "                if column == 'CustomerCode':\n",
    "                    data_df[column] = data_df[column].astype(str)\n",
    "            return data_df\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    def get_training_id(self):\n",
    "        sql = \"SELECT MAX(TrainingId) FROM LapseMaster\"\n",
    "        try:\n",
    "            self.cursor.execute(sql)\n",
    "            training_id = self.cursor.fetchone()[0] + 1\n",
    "            return training_id\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    def update_lapse_customer_shopping_history(self, training_id):\n",
    "        sql = f'EXEC SP_LapsCustomerShoppingHistoryModified {training_id}'\n",
    "        try:\n",
    "            self.cursor.execute(sql)\n",
    "            self.connection.commit()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "def _change_to_datetime(df):\n",
    "    cols = df.columns[1:]\n",
    "    for col in cols:\n",
    "        df[col] = pd.to_datetime(df[col], format='%Y-%m-%d')\n",
    "    return df\n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "    def _init_(self, purchase_date):\n",
    "        # self.file_location = file_location\n",
    "        # self.xl_file = pd.ExcelFile(self.file_location, engine='openpyxl')\n",
    "        # self.purchase_date = pd.read_excel(self.xl_file, 'Trainee Data', engine='openpyxl')\n",
    "        # self.purchase_date = self.purchase_date.astype({'CustomerCode': 'str'})\n",
    "        self.purchase_date = purchase_date\n",
    "        self.purchase_date = self.purchase_date.iloc[:, 0:9]\n",
    "        self.purchase_date = _change_to_datetime(self.purchase_date)\n",
    "        self.purchase_date = self._data_preprocessor()\n",
    "\n",
    "    def _data_preprocessor(self):\n",
    "        purchase_date = self.purchase_date\n",
    "        purchase_date.dropna(inplace=True)\n",
    "        purchase_date.rename(columns={\n",
    "            #     'CustomerCode': 'customer_code',\n",
    "            '1': 'day_1',\n",
    "            '2': 'day_2',\n",
    "            '3': 'day_3',\n",
    "            '4': 'day_4',\n",
    "            '5': 'day_5',\n",
    "            '6': 'day_6',\n",
    "            '7': 'day_7',\n",
    "            '8': 'day_8'\n",
    "        }, inplace=True)\n",
    "        purchase_date['dd_0'] = (purchase_date['day_1'] - purchase_date['day_2']).dt.days\n",
    "        purchase_date['dd_1'] = (purchase_date['day_2'] - purchase_date['day_3']).dt.days\n",
    "        purchase_date['dd_2'] = (purchase_date['day_3'] - purchase_date['day_4']).dt.days\n",
    "        purchase_date['dd_3'] = (purchase_date['day_4'] - purchase_date['day_5']).dt.days\n",
    "        purchase_date['dd_4'] = (purchase_date['day_5'] - purchase_date['day_6']).dt.days\n",
    "        purchase_date['dd_5'] = (purchase_date['day_6'] - purchase_date['day_7']).dt.days\n",
    "        purchase_date['dd_6'] = (purchase_date['day_7'] - purchase_date['day_8']).dt.days\n",
    "        purchase_date['dd_mean'] = purchase_date.iloc[:, 9:15].mean(axis=1)\n",
    "        purchase_date['dd_std'] = purchase_date.iloc[:, 9:15].std(axis=1)\n",
    "        purchase_date['dd_max'] = purchase_date.iloc[:, 9:15].max(axis=1)\n",
    "        purchase_date['dd_min'] = purchase_date.iloc[:, 9:15].min(axis=1)\n",
    "        purchase_date['dd_range'] = purchase_date['dd_max'] - purchase_date['dd_min']\n",
    "        purchase_date['ddc_0'] = (purchase_date['day_1'] - purchase_date['day_2']).dt.days\n",
    "        purchase_date['ddc_1'] = (purchase_date['day_2'] - purchase_date['day_3']).dt.days\n",
    "        purchase_date['ddc_2'] = (purchase_date['day_2'] - purchase_date['day_4']).dt.days\n",
    "        purchase_date['ddc_3'] = (purchase_date['day_2'] - purchase_date['day_5']).dt.days\n",
    "        purchase_date['ddc_4'] = (purchase_date['day_2'] - purchase_date['day_6']).dt.days\n",
    "        purchase_date['ddc_5'] = (purchase_date['day_2'] - purchase_date['day_7']).dt.days\n",
    "        purchase_date['ddc_6'] = (purchase_date['day_2'] - purchase_date['day_8']).dt.days\n",
    "        # purchase_date['test_target'] = (purchase_date['day_1'] - purchase_date['day_2']).dt.days\n",
    "        self.predicted_df = purchase_date[['CustomerCode']]\n",
    "        # self.test_df['actual'] = 0\n",
    "        # self.test_df.loc[(self.test_df['test_target']>0) & (self.test_df['test_target']<=15), 'actual'] = 1\n",
    "        # self.test_df.loc[(self.test_df['test_target']>15) & (self.test_df['test_target']<=30), 'actual'] = 2\n",
    "        # self.test_df.loc[self.test_df['test_target'] > 30, 'actual'] = 1\n",
    "        # self.test_df = self.test_df.drop(columns=['test_target'])\n",
    "        purchase_date = purchase_date.drop(\n",
    "            columns=['day_1', 'day_2', 'day_3', 'day_4', 'day_5', 'day_6', 'day_7', 'day_8'])\n",
    "        purchase_date['target'] = 0\n",
    "        purchase_date.loc[purchase_date['dd_0'] > 30, 'target'] = 1\n",
    "        self.dd0 = purchase_date['dd_0'].to_list()\n",
    "        purchase_date = purchase_date.drop(columns=['dd_0'])\n",
    "        return purchase_date\n",
    "\n",
    "    def get_training_data(self):\n",
    "        X, y = self.purchase_date.drop('target', axis=1), self.purchase_date.target\n",
    "        customers = X['CustomerCode'].to_list()\n",
    "        X = X.drop(columns=['CustomerCode'])\n",
    "        X.insert(0, 'dd_0', self.dd0)\n",
    "        self.X_to_pred = X.drop(columns=['dd_6'])\n",
    "        X_train = X.drop(columns=['dd_0'])\n",
    "        sm = BorderlineSMOTE(random_state=1)\n",
    "        X_train, y = sm.fit_resample(X_train, y)\n",
    "        return X_train, y\n",
    "\n",
    "    def fit(self):\n",
    "        X_train, y = self.get_training_data()\n",
    "        self.xgb_model = xgb.XGBClassifier().fit(X_train, y)\n",
    "\n",
    "    def predict(self):\n",
    "        self.predicted_df['predicted'] = self.xgb_model.predict(self.X_to_pred)\n",
    "        return self.predicted_df\n",
    "\n",
    "\n",
    "def main():\n",
    "    lapse_db_util = LapseDBUtil()\n",
    "    # lapse_db_util.create_table(\"LapseMaster\")\n",
    "    # lapse_db_util.create_table(\"LapsePredictedGroup\")\n",
    "    # lapse_db_util.create_table(\"LapseDetails\")\n",
    "\n",
    "    # xl_file = pd.ExcelFile(\"../data/Customer Sales Data For AI.xlsx\", engine='openpyxl')\n",
    "    # purchase_date = pd.read_excel(xl_file, 'Trainee Data', engine='openpyxl', converters={'CustomerCode': str})\n",
    "    print('Data Loading.......\\n')\n",
    "    purchase_date = lapse_db_util.get_purchase_dates()\n",
    "    print('Data Loading Completed.......\\n')\n",
    "    dl = DataLoader(purchase_date)\n",
    "    print('Training Started.......\\n')\n",
    "    dl.fit()\n",
    "    print('Training Completed.......\\n')\n",
    "    predicted_df = dl.predict()\n",
    "    predicted_df = predicted_df[['CustomerCode', 'predicted']]\n",
    "    training_id = lapse_db_util.get_training_id()\n",
    "    predicted_df.insert(0, 'training_id', training_id)\n",
    "    predicted_df.to_csv('csv_files/predicted_df.csv', index=False)\n",
    "    master_data_df = get_master_data(training_id, pd.to_datetime(datetime.today().strftime(\"%Y-%m-%d %H:%M:%S\")), pd.to_datetime(datetime.today().strftime(\"%Y-%m-%d %H:%M:%S\")), purchase_date)\n",
    "    master_data_df.to_csv('csv_files/master_data_df.csv', index=False)\n",
    "    group_info_df = get_group_info([0, 1],\n",
    "                                   [\"Less than 30 days\", \"Greater than 30 days\"],\n",
    "                                   [datetime.today(), datetime.today()])\n",
    "    print('Writing in LapseDB.......\\n')\n",
    "    # lapse_db_util.insert(\"LapseMaster\", master_data_df)\n",
    "    # lapse_db_util.insert(\"LapsePredictedGroup\", group_info_df)\n",
    "    # lapse_db_util.insert(\"LapseDetails\", predicted_df)\n",
    "    lapse_db_util.update_lapse_customer_shopping_history(training_id)\n",
    "    print('Done.......\\n')\n",
    "\n",
    "\n",
    "if _name_ == '_main_':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
